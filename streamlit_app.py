import json
import streamlit as st
import os
import tempfile
import time
from datetime import datetime
import base64
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
import subprocess
import sys
import logging
import requests
import psutil
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from config_ml import (
    metabolites_selected_onco, metabolites_selected_CVD,
    metabolites_selected_Liv, metabolites_selected_PULM,
    metabolites_selected_RA, thresholds, TRAIN_PARAMS
)
import joblib

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    filename='report_generator.log'
)

def setup_chrome_driver():
    """Configure Chrome WebDriver with extended timeout settings"""
    chrome_options = Options()
    chrome_options.add_argument("--headless=new")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=1920,1080")
    
    driver = webdriver.Chrome(options=chrome_options)
    driver.set_page_load_timeout(55)
    driver.set_script_timeout(40)
    return driver

def is_dash_process(process):
    """Check if process is our Dash application"""
    try:
        cmdline = ' '.join(process.cmdline()).lower()
        return ('main.py' in cmdline or 'dash' in cmdline) and 'python' in process.name().lower()
    except (psutil.NoSuchProcess, psutil.AccessDenied, AttributeError):
        return False

def kill_dash_app(port=8050):
    """Kill only the Dash app running on specified port"""
    for proc in psutil.process_iter(['pid', 'name']):
        try:
            # Cross-platform way to check connections
            connections = proc.net_connections()
            for conn in connections:
                if conn.laddr.port == port and is_dash_process(proc):
                    try:
                        proc.terminate()
                        proc.wait(timeout=5)
                    except (psutil.NoSuchProcess, psutil.TimeoutExpired):
                        try:
                            proc.kill()
                        except:
                            pass
                    break
        except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.Error):
            continue

def wait_for_dash_app(timeout=45):
    """Wait for Dash app to become ready with content verification"""
    start_time = time.time()
    
    while time.time() - start_time < timeout:
        try:
            # First check if port is in use
            port_in_use = False
            for proc in psutil.process_iter(['pid']):
                try:
                    for conn in proc.connections():
                        if conn.laddr.port == 8050:
                            port_in_use = True
                            break
                except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.Error):
                    continue
            
            if not port_in_use:
                time.sleep(2)
                continue
                
            # Then check health endpoint
            health_response = requests.get("http://localhost:8050/_alive", timeout=5)
            if health_response.status_code == 200:
                content_response = requests.get("http://localhost:8050", timeout=10)
                if "Patient Report" in content_response.text:
                    return True
        except requests.exceptions.RequestException:
            time.sleep(3)
    
    return False
import pandas as pd

def calculate_metabolite_ratios(metabolomic_data):
    """Calculate all metabolite ratios from raw metabolomic data"""
    # Read data
    data = pd.read_excel(metabolomic_data)
    
    # Replace all negative values with 0 in the entire DataFrame
    data = data.map(lambda x: 0 if isinstance(x, (int, float)) and x < 0 else x)
    
    try:
        # Prepare all new columns in a dictionary first
        new_columns = {}
        
        # Acylcarnitines
        new_columns['(C2+C3)/C0'] = (data['C2'] + data['C3']) / data['C0']
        new_columns['CACT Deficiency (NBS)'] = data['C0'] / (data['C16'] + data['C18'])
        new_columns['CPT-1 Deficiency (NBS)'] = (data['C16'] + data['C18']) / data['C0']
        new_columns['CPT-2 Deficiency (NBS)'] = (data['C16'] + data['C18']) / data['C2']
        new_columns['EMA (NBS)'] = data['C4'] / data['C8']
        new_columns['IBD Deficiency (NBS)'] = data['C4'] / data['C2']
        new_columns['IVA (NBS)'] = data['C5'] / data['C2']
        new_columns['LCHAD Deficiency (NBS)'] = data['C16-OH'] / data['C16']
        new_columns['MA (NBS)'] = data['C3'] / data['C2']
        new_columns['MC Deficiency (NBS)'] = data['C16'] / data['C3']
        new_columns['MCAD Deficiency (NBS)'] = data['C8'] / data['C2']
        new_columns['MCKAT Deficiency (NBS)'] = data['C8'] / data['C10']
        new_columns['MMA (NBS)'] = data['C3'] / data['C0']
        new_columns['PA (NBS)'] = data['C3'] / data['C16']
        new_columns['Ð¡2/Ð¡0'] = data['C2'] / data['C0']
        new_columns['Ratio of Acetylcarnitine to Carnitine'] = data['C2'] / data['C0']
        
        # Calculate sums once to reuse
        sum_AC_OHs = (data['C5-OH'] + data['C14-OH'] + data['C16-1-OH'] + 
                     data['C16-OH'] + data['C18-1-OH'] + data['C18-OH'])
        sum_ACs = (data['C0'] + data['C10'] + data['C10-1'] + data['C10-2'] + 
                  data['C12'] + data['C12-1'] + data['C14'] + data['C14-1'] + 
                  data['C14-2'] + data['C16'] + data['C16-1'] + data['C18'] + 
                  data['C18-1'] + data['C18-2'] + data['C2'] + data['C3'] + 
                  data['C4'] + data['C5'] + data['C5-1'] + data['C5-DC'] + 
                  data['C6'] + data['C6-DC'] + data['C8'] + data['C8-1'])
        
        new_columns['Ratio of AC-OHs to ACs'] = sum_AC_OHs / sum_ACs
        
        Ð¡Ð”Ðš = (data['C14'] + data['C14-1'] + data['C14-2'] + data['C14-OH'] + 
               data['C16'] + data['C16-1'] + data['C16-1-OH'] + data['C16-OH'] + 
               data['C18'] + data['C18-1'] + data['C18-1-OH'] + data['C18-2'] + 
               data['C18-OH'])
        Ð¡Ð¡Ðš = (data['C6'] + data['C6-DC'] + data['C8'] + data['C8-1'] + 
               data['C10'] + data['C10-1'] + data['C10-2'] + data['C12'] + 
               data['C12-1'])
        Ð¡ÐšÐš = (data['C2'] + data['C3'] + data['C4'] + data['C5'] + data['C5-1'] + 
               data['C5-DC'] + data['C5-OH'])
        
        new_columns['Ð¡Ð”Ðš'] = Ð¡Ð”Ðš
        new_columns['Ð¡Ð¡Ðš'] = Ð¡Ð¡Ðš
        new_columns['Ð¡ÐšÐš'] = Ð¡ÐšÐš
        new_columns['Ratio of Medium-Chain to Long-Chain ACs'] = Ð¡Ð¡Ðš / Ð¡Ð”Ðš
        new_columns['Ratio of Short-Chain to Long-Chain ACs'] = Ð¡ÐšÐš / Ð¡Ð”Ðš
        new_columns['Ratio of Short-Chain to Medium-Chain ACs'] = Ð¡ÐšÐš / Ð¡Ð¡Ðš
        new_columns['SBCAD Deficiency (NBS)'] = data['C5'] / data['C0']
        new_columns['SCAD Deficiency (NBS)'] = data['C4'] / data['C3']
        new_columns['Sum of ACs'] = sum_AC_OHs + sum_ACs - data['C0']  # Subtract C0 since it's included in sum_ACs
        new_columns['Sum of ACs + Ð¡0'] = sum_AC_OHs + sum_ACs
        new_columns['Sum of ACs/C0'] = (sum_AC_OHs + sum_ACs - data['C0']) / data['C0']
        
        new_columns['Sum of MUFA-ACs'] = (data['C16-1-OH'] + data['C18-1-OH'] + 
                                        data['C10-1'] + data['C12-1'] + 
                                        data['C14-1'] + data['C16-1'] + 
                                        data['C18-1'] + data['C8-1'] + 
                                        data['C5-1'])
        new_columns['Sum of PUFA-ACs'] = data['C10-2'] + data['C14-2'] + data['C18-2']
        new_columns['TFP Deficiency (NBS)'] = data['C16'] / data['C16-OH']
        new_columns['VLCAD Deficiency (NBS)'] = data['C14-1'] / data['C16']
        new_columns['(C6+C8+C10)/C2'] = (data['C6'] + data['C8'] + data['C10']) / data['C2']
        new_columns['2MBG (NBS)'] = data['C5'] / data['C3']
        new_columns['Carnitine Uptake Defect (NBS)'] = (data['C0'] + data['C2'] + data['C3'] + 
                                                       data['C16'] + data['C18'] + 
                                                       data['C18-1']) / data['Citrulline']

        new_columns['C2 / C3'] = data['C2'] / data['C3']
        # NO- and urea cycle
        new_columns['GABR'] = data['Arginine'] / (data['Ornitine'] + data['Citrulline'])
        new_columns['Orn Synthesis'] = data['Ornitine'] / data['Arginine']
        new_columns['AOR'] = data['Arginine'] / data['Ornitine']
        new_columns['ADMA/(Adenosin+Arginine)'] = data['ADMA'] / (data['Adenosin'] + data['Arginine'])
        new_columns["Asymmetrical Arg Methylation"] = data['ADMA'] / data['Arginine']
        new_columns['Symmetrical Arg Methylation'] = data['TotalDMA (SDMA)'] / data['Arginine']
        new_columns['(Arg+HomoArg)/ADMA'] = (data['Arginine'] + data['Homoarginine']) / data['ADMA']
        new_columns['ADMA / NMMA'] = data['ADMA'] / data['NMMA']
        new_columns['NO-Synthase Activity'] = data['Citrulline'] / data['Arginine']
        new_columns['OTC Deficiency (NBS)'] = data['Ornitine'] / data['Citrulline']
        new_columns['Ratio of HArg to ADMA'] = data['Homoarginine'] / data['ADMA']
        new_columns['Ratio of HArg to SDMA'] = data['Homoarginine'] / data['TotalDMA (SDMA)']
        new_columns['Sum of Asym. and Sym. Arg Methylation'] = (data['TotalDMA (SDMA)'] + data['ADMA']) / data['Arginine']
        new_columns['Sum of Dimethylated Arg'] = data['TotalDMA (SDMA)'] + data['ADMA']
        new_columns['Cit Synthesis'] = data['Citrulline'] / data['Ornitine']
        new_columns['CPS Deficiency (NBS)'] = data['Citrulline'] / data['Phenylalanine']
        new_columns['HomoArg Synthesis'] = data['Homoarginine'] / (data['Arginine'] + data['Lysine'])
        new_columns['Ratio of Pro to Cit'] = data['Proline'] / data['Citrulline']

        # Tryptophan metabolism
        new_columns['Kynurenine / Trp'] = data['Kynurenine'] / data['Tryptophan']
        new_columns['Serotonin / Trp'] = data['Serotonin'] / data['Tryptophan']
        new_columns['Trp/(Kyn+QA)'] = data['Tryptophan'] / (data['Kynurenine'] + data['Quinolinic acid'])
        new_columns['Kyn/Quin'] = data['Kynurenine'] / data['Quinolinic acid']
        new_columns['Quin/HIAA'] = data['Quinolinic acid'] / data['HIAA']
        new_columns['Tryptamine / IAA'] = data['Tryptamine'] / data['Indole-3-acetic acid']
        new_columns['Kynurenic acid / Kynurenine'] = data['Kynurenic acid'] / data['Kynurenine']

        # Amino acids
        new_columns['Asn Synthesis'] = data['Asparagine'] / data['Aspartic acid']
        new_columns['Glutamine/Glutamate'] = data['Glutamine'] / data['Glutamic acid']
        new_columns['Gly Synthesis'] = data['Glycine'] / data['Serine']
        new_columns['GSG Index'] = data['Glutamic acid'] / (data['Serine'] + data['Glycine'])
        new_columns['Sum of Aromatic AAs'] = data['Phenylalanine'] + data['Tyrosin']
        new_columns['BCAA'] = data['Summ Leu-Ile'] + data['Valine']
        new_columns['BCAA/AAA'] = (data['Valine'] + data['Summ Leu-Ile']) / (data['Phenylalanine'] + data['Tyrosin'])
        new_columns['Alanine / Valine'] = data['Alanine'] / data['Valine']
        new_columns['DLD (NBS)'] = data['Proline'] / data['Phenylalanine']
        new_columns['MTHFR Deficiency (NBS)'] = data['Methionine'] / data['Phenylalanine']
        
        # Calculate sums once for AA ratios
        sum_non_essential = (data['Alanine'] + data['Arginine'] + data['Asparagine'] + 
                           data['Aspartic acid'] + data['Glutamine'] + 
                           data['Glutamic acid'] + data['Glycine'] + data['Proline'] + 
                           data['Serine'] + data['Tyrosin'])
        sum_essential = (data['Histidine'] + data['Summ Leu-Ile'] + data['Lysine'] + 
                        data['Methionine'] + data['Phenylalanine'] + 
                        data['Threonine'] + data['Tryptophan'] + data['Valine'])
        
        new_columns['Ratio of Non-Essential to Essential AAs'] = sum_non_essential / sum_essential
        new_columns['Sum of AAs'] = sum_non_essential + sum_essential
        new_columns['Sum of Essential Aas'] = sum_essential
        new_columns['Sum of Non-Essential AAs'] = sum_non_essential
        new_columns['Sum of Solely Glucogenic AAs'] = (data['Alanine'] + data['Arginine'] + 
                                                     data['Asparagine'] + data['Aspartic acid'] + 
                                                     data['Glutamine'] + data['Glutamic acid'] + 
                                                     data['Glycine'] + data['Histidine'] + 
                                                     data['Methionine'] + data['Proline'] + 
                                                     data['Serine'] + data['Threonine'] + 
                                                     data['Valine'])
        new_columns['Sum of Solely Ketogenic AAs'] = data['Summ Leu-Ile'] + data['Lysine']
        new_columns['Valinemia (NBS)'] = data['Valine'] / data['Phenylalanine']
        new_columns['Carnosine Synthesis'] = data['Carnosine'] / data['Histidine']
        new_columns['Histamine Synthesis'] = data['Histamine'] / data['Histidine']

        # Betaine_choline metabolism
        new_columns['Betaine/choline'] = data['Betaine'] / data['Choline']
        new_columns['Methionine + Taurine'] = data['Methionine'] + data['Taurine']
        new_columns['DMG / Choline'] = data['DMG'] / data['Choline']
        new_columns['TMAO Synthesis'] = data['TMAO'] / (data['Betaine'] + data['C0'] + data['Choline'])
        new_columns['TMAO Synthesis (direct)'] = data['TMAO'] / data['Choline']
        new_columns['Met Oxidation'] = data['Methionine-Sulfoxide'] / data['Methionine']

        # Vitamins
        new_columns['Riboflavin / Pantothenic'] = data['Riboflavin'] / data['Pantothenic']

        # ADDED: Oncology-specific ratios that were missing
        new_columns['Arg/ADMA'] = data['Arginine'] / data['ADMA']
        new_columns['Arg/Orn+Cit'] = data['Arginine'] / (data['Ornitine'] + data['Citrulline'])
        new_columns['Glutamine/Glutamate'] = data['Glutamine'] / data['Glutamic acid']
        new_columns['Pro/Cit'] = data['Proline'] / data['Citrulline']
        new_columns['Kyn/Trp'] = data['Kynurenine'] / data['Tryptophan']
        new_columns['Trp/Kyn'] = data['Tryptophan'] / data['Kynurenine']
        
        # Arthritis
        new_columns['Phe/Tyr'] = data['Phenylalanine'] / data['Tyrosin']
        new_columns['Glycine/Serine'] = data['Glycine'] / data['Serine']
        # Lungs
        new_columns['C4 / C2'] = data['C4'] / data['C2']
        new_columns['Valine / Alanine'] = data['Valine'] / data['Alanine']
        # Liver
        new_columns['C0/(C16+C18)'] = data['C0'] / (data['C16'] + data['C18'])
        new_columns['(Leu+IsL)/(C3+Ð¡5+Ð¡5-1+C5-DC)'] = (data['Summ Leu-Ile']) / (data['C3'] + data['C5'] + data['C5-1'] + data['C5-DC'])
        new_columns['Val/C4'] = data['Valine'] / data['C4']

        # Convert the dictionary to a DataFrame and concatenate with original data
        new_data = pd.DataFrame(new_columns)
        data = pd.concat([data, new_data], axis=1)

        # Drop Group column if it exists
        if 'Group' in data.columns:
            data = data.drop('Group', axis=1)

        return data

    except Exception as e:
        print(f"Error calculating metabolite ratios: {str(e)}")
        return None

def prepare_final_dataframe(risk_params_data, metabolomic_data_with_ratios):
    # Load the data
    risk_params = pd.read_excel(risk_params_data)
    metabolic_data = pd.read_excel(metabolomic_data_with_ratios)
    
    # Get values for each marker from metabolomic data
    values_conc = []
    for metabolite in risk_params['ÐœÐ°Ñ€ÐºÐµÑ€ / Ð¡Ð¾Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ðµ']:
        try:
            value = metabolic_data.loc[0, metabolite]
            # Handle negative and infinite values
            if pd.isna(value) or np.isinf(value):
                values_conc.append(np.nan)
            elif value < 0:
                values_conc.append(0)
            else:
                values_conc.append(value)
        except KeyError:
            values_conc.append(np.nan)  # Handle missing metabolites
    
    risk_params['Patient'] = values_conc
    
    # Drop rows with infinite or NaN values in Patient column
    risk_params = risk_params[~risk_params['Patient'].isin([np.inf, -np.inf]) & 
                  ~risk_params['Patient'].isna()].copy()
    
    subgroup_list=[]
    subgroup_scores=[]
    categories=risk_params['ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ñ'].unique()
    for category in categories:
        data_category=risk_params[risk_params['ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ñ']==category]
        metabolite_inputs=[]
        for index, row in data_category.iterrows():
            metabolite_input=0
            weight=data_category.loc[index, 'Ð²ÐµÑÐ°']
            patient_value=data_category.loc[index, 'Patient']
            norm_1=data_category.loc[index, 'norm_1']
            norm_2=data_category.loc[index, 'norm_2']
            risk_1=data_category.loc[index, 'High_risk_1']
            risk_2=data_category.loc[index, 'High_risk_2']
            metab_group=data_category.loc[index, 'Ð“Ñ€ÑƒÐ¿Ð¿Ð°_Ð¼ÐµÑ‚Ð°Ð±']
            if metab_group==0:
                if norm_1<=patient_value<=norm_2:
                    metabolite_input=0
                elif risk_1<=patient_value<norm_1 or norm_2<patient_value<=risk_2:
                    metabolite_input=1
                else:
                    metabolite_input=2
            elif metab_group==1:
                if patient_value<=norm_2:
                    metabolite_input=0
                elif norm_2<patient_value<=risk_2:
                    metabolite_input=1
                else:
                    metabolite_input=2
            else:
                if norm_1<=patient_value:
                    metabolite_input=0
                elif risk_1<=patient_value<norm_1:
                    metabolite_input=1
                else:
                    metabolite_input=2
            metabolite_inputs.append(metabolite_input*weight)
            max_score=data_category['Ð²ÐµÑÐ°'].sum()*2
            subgroup_score=sum(metabolite_inputs)/max_score*100
        subgroup_scores.append(subgroup_score)
        subgroup_list.append(category)
    
    # in risk_params make column Subgroup_score and for each row where [ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ñ] is in subgroup_list, [Subgroup_score] is subgroup_scores[subgroup_list.index([ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ñ])]
    risk_params['Subgroup_score'] = np.nan
    for index, row in risk_params.iterrows():
        if row['ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ñ'] in subgroup_list:
            risk_params.loc[index, 'Subgroup_score'] = subgroup_scores[subgroup_list.index(row['ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ñ'])]
    
    # in risk_params make column Subgroup_score and for each row where [ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ñ] is in subgroup_list, [Subgroup_score] is subgroup_scores[subgroup_list.index([ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ñ])]
    risk_params['Subgroup_score'] = np.nan
    for index, row in risk_params.iterrows():
        if row['ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ñ'] in subgroup_list:
            risk_params.loc[index, 'Subgroup_score'] = subgroup_scores[subgroup_list.index(row['ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ñ'])]
    return risk_params


def probability_to_score(prob, threshold):
    prob = min(max(prob, 0), 1)
    if prob < threshold:
        score = 5 * prob / threshold
    else:
        score = 5 + 5 * (prob - threshold) / (1 - threshold)
    return 10- round(score, 0)



def calculate_risks(risk_params_data, metabolic_data_with_ratios):
    """
    Calculate combined risks using:
    - ML models for specific groups (Onco, CVD, Liver, Pulmo, RA)
    - Parameter-based method for other groups
    Returns DataFrame with columns: ['Ð“Ñ€ÑƒÐ¿Ð¿Ð° Ñ€Ð¸ÑÐºÐ°', 'Ð Ð¸ÑÐº-ÑÐºÐ¾Ñ€', 'ÐœÐµÑ‚Ð¾Ð´ Ð¾Ñ†ÐµÐ½ÐºÐ¸']
    """
    # Ð“Ñ€ÑƒÐ¿Ð¿Ñ‹, Ð´Ð»Ñ ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ñ… Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ML Ð¼Ð¾Ð´ÐµÐ»Ð¸
    ml_only_groups = {
        "ÐžÑ†ÐµÐ½ÐºÐ° Ð¿Ñ€Ð¾Ð»Ð¸Ñ„ÐµÑ€Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ñ… Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ¾Ð²",
        "Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ ÑÐµÑ€Ð´ÐµÑ‡Ð½Ð¾-ÑÐ¾ÑÑƒÐ´Ð¸ÑÑ‚Ð¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹",
        "Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ð¿ÐµÑ‡ÐµÐ½Ð¸",
        "Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð´Ñ‹Ñ…Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹",
        "Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð¸Ð¼Ð¼ÑƒÐ½Ð½Ð¾Ð³Ð¾ Ð¼ÐµÑ‚Ð°Ð±Ð¾Ð»Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð±Ð°Ð»Ð°Ð½ÑÐ°"
    }
    
        # --- Part 1: Validate input data indices ---
    def ensure_unique_index(df, df_name):
        if not df.index.is_unique:
            print(f"ÐŸÑ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ðµ: ÐÐ°Ð¹Ð´ÐµÐ½Ñ‹ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ñ‹ Ð² Ð¸Ð½Ð´ÐµÐºÑÐµ {df_name}. Ð¡Ð±Ñ€Ð°ÑÑ‹Ð²Ð°ÑŽ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚.")
            return df[~df.index.duplicated(keep='first')]
        return df
    
    metabolic_data_with_ratios = ensure_unique_index(metabolic_data_with_ratios, "metabolic_data_with_ratios")
    risk_params_data = ensure_unique_index(risk_params_data, "risk_params_data")

    # --- Part 1: Model-based risk calculation ---
    models_info = {
        "ÐžÑ†ÐµÐ½ÐºÐ° Ð¿Ñ€Ð¾Ð»Ð¸Ñ„ÐµÑ€Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ñ… Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ¾Ð²": {
            "model_path": os.path.join(os.path.dirname(__file__), "models", "Onco_healthy_RF_0907.pkl"),
            "features": metabolites_selected_onco
        },
        "Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ ÑÐµÑ€Ð´ÐµÑ‡Ð½Ð¾-ÑÐ¾ÑÑƒÐ´Ð¸ÑÑ‚Ð¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹": {
            "model_path": os.path.join(os.path.dirname(__file__), "models", "CVD_healthy_RF_0907.pkl"),
            "features": metabolites_selected_CVD
        },
        "Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ð¿ÐµÑ‡ÐµÐ½Ð¸": {
            "model_path": os.path.join(os.path.dirname(__file__), "models", "Liver_healthy_RF_0907.pkl"),
            "features": metabolites_selected_Liv
        },
        "Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð´Ñ‹Ñ…Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹": {
            "model_path": os.path.join(os.path.dirname(__file__), "models", "Pulmo_healthy_RF_0907.pkl"),
            "features": metabolites_selected_PULM
        },
        "Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð¸Ð¼Ð¼ÑƒÐ½Ð½Ð¾Ð³Ð¾ Ð¼ÐµÑ‚Ð°Ð±Ð¾Ð»Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð±Ð°Ð»Ð°Ð½ÑÐ°": {
            "model_path": os.path.join(os.path.dirname(__file__), "models", "RA_healthy_RF_0907.pkl"),
            "features": metabolites_selected_RA
        }
    }

    # Initialize results
    results = []

    # Read metabolic data
    row = metabolic_data_with_ratios.iloc[0]  # Assuming single row input

    for idx, row in metabolic_data_with_ratios.iterrows():
        for disease, info in models_info.items():
            try:
                model = joblib.load(info["model_path"])
                threshold = thresholds[disease]
                X_row = pd.DataFrame([row[info["features"]]], columns=info["features"])
                # Clean data - replace inf and large values
                X_row = X_row.replace([np.inf, -np.inf], np.nan)
                X_row = X_row.fillna(0)
                X_row = X_row.clip(-1e10, 1e10)
                
                # Convert to float32 to match typical model expectations
                X_row = X_row.astype(np.float32)
                pred_proba = model.predict_proba(X_row)[0][1]
                score = probability_to_score(pred_proba, threshold)

                results.append({
                    "Ð“Ñ€ÑƒÐ¿Ð¿Ð° Ñ€Ð¸ÑÐºÐ°": disease,
                    "Ð Ð¸ÑÐº-ÑÐºÐ¾Ñ€": score ,
                    "ÐœÐµÑ‚Ð¾Ð´ Ð¾Ñ†ÐµÐ½ÐºÐ¸": "ML Ð¼Ð¾Ð´ÐµÐ»ÑŒ"
                })

            except Exception as e:
                print(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð² Ð¼Ð¾Ð´ÐµÐ»Ð¸ {disease}: {e}")
                results.append({
                    "Ð“Ñ€ÑƒÐ¿Ð¿Ð° Ñ€Ð¸ÑÐºÐ°": disease,
                    "Ð Ð¸ÑÐº-ÑÐºÐ¾Ñ€": None,
                    "ÐœÐµÑ‚Ð¾Ð´ Ð¾Ñ†ÐµÐ½ÐºÐ¸": "ML Ð¼Ð¾Ð´ÐµÐ»ÑŒ"
                })
       

    # 2. Process other groups with parameter-based method

    
    # Filter out ML-only groups
    other_groups = set(risk_params_data['Ð“Ñ€ÑƒÐ¿Ð¿Ð°_Ñ€Ð¸ÑÐºÐ°'].unique()) - ml_only_groups
    
    if other_groups:
        # Prepare parameter risk_params_data
        values_conc = []
        for metabolite in risk_params_data['ÐœÐ°Ñ€ÐºÐµÑ€ / Ð¡Ð¾Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ðµ']:
            try:
                value = row[metabolite]
                if pd.isna(value) or np.isinf(value):
                    values_conc.append(np.nan)
                elif value < 0:
                    values_conc.append(0)
                else:
                    values_conc.append(value)
            except KeyError:
                values_conc.append(np.nan)
        
        risk_params_data['Patient'] = values_conc
        risk_params_data = risk_params_data[~risk_params_data['Patient'].isin([np.inf, -np.inf]) & ~risk_params_data['Patient'].isna()].copy()
        
        # Calculate scores for remaining groups
        for risk_group in other_groups:
            risk_params_data_group = risk_params_data[risk_params_data['Ð“Ñ€ÑƒÐ¿Ð¿Ð°_Ñ€Ð¸ÑÐºÐ°'] == risk_group]
            if len(risk_params_data_group) == 0:
                continue
                
            metabolite_inputs = []
            for index, row_group in risk_params_data_group.iterrows():
                metabolite_input = 0
                weight = row_group['Ð²ÐµÑÐ°']
                patient_value = row_group['Patient']
                norm_1 = row_group['norm_1']
                norm_2 = row_group['norm_2']
                risk_1 = row_group['High_risk_1']
                risk_2 = row_group['High_risk_2']
                metab_group = row_group['Ð“Ñ€ÑƒÐ¿Ð¿Ð°_Ð¼ÐµÑ‚Ð°Ð±']
                
                if metab_group == 0:
                    if norm_1 <= patient_value <= norm_2:
                        metabolite_input = 0
                    elif risk_1 <= patient_value < norm_1 or norm_2 < patient_value <= risk_2:
                        metabolite_input = 1
                    else:
                        metabolite_input = 2
                elif metab_group == 1:
                    if patient_value <= norm_2:
                        metabolite_input = 0
                    elif norm_2 < patient_value <= risk_2:
                        metabolite_input = 1
                    else:
                        metabolite_input = 2
                else:
                    if norm_1 <= patient_value:
                        metabolite_input = 0
                    elif risk_1 <= patient_value < norm_1:
                        metabolite_input = 1
                    else:
                        metabolite_input = 2
                
                metabolite_inputs.append(metabolite_input * weight)
            
            max_score = risk_params_data_group['Ð²ÐµÑÐ°'].sum() * 2
            group_score = 10 - sum(metabolite_inputs) / max_score * 10
            results.append({
                "Ð“Ñ€ÑƒÐ¿Ð¿Ð° Ñ€Ð¸ÑÐºÐ°": risk_group,
                "Ð Ð¸ÑÐº-ÑÐºÐ¾Ñ€": np.round(group_score, 0),
                "ÐœÐµÑ‚Ð¾Ð´ Ð¾Ñ†ÐµÐ½ÐºÐ¸": "ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹"
            })

    # Create final DataFrame
    result_df = pd.DataFrame(results)
    
    # Sort by risk score (descending) and group name
    result_df.sort_values(['Ð“Ñ€ÑƒÐ¿Ð¿Ð° Ñ€Ð¸ÑÐºÐ°'], ascending=True, inplace=True)
    
    return result_df[['Ð“Ñ€ÑƒÐ¿Ð¿Ð° Ñ€Ð¸ÑÐºÐ°', 'Ð Ð¸ÑÐº-ÑÐºÐ¾Ñ€', 'ÐœÐµÑ‚Ð¾Ð´ Ð¾Ñ†ÐµÐ½ÐºÐ¸']].reset_index(drop=True)



def generate_pdf_report(patient_info, risk_scores_path, risk_params_exp_path, metabolomic_data_with_ratios_path, output_dir):
    """Generate PDF report with proper error handling"""
    dash_process = None
    driver = None
    
    try:
        
        # Clean up any existing Dash instance
        kill_dash_app(8050)
        time.sleep(2)
        
        # Start new Dash process with all needed data
        dash_command = [
            sys.executable,
            "main.py",
            "--name", patient_info['name'],
            "--age", str(patient_info['age']),
            "--gender", patient_info['gender'],
            "--date", patient_info['date'],
            "--risk_scores", risk_scores_path,
            "--risk_params", risk_params_exp_path,
            "--metabolomic_data", metabolomic_data_with_ratios_path,
        ]
        
        dash_process = subprocess.Popen(
            dash_command,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        
        # Wait for Dash app to be ready
        if not wait_for_dash_app():
            raise Exception("Dash app failed to start or load content")
        
        # Generate PDF
        driver = setup_chrome_driver()
        driver.get("http://localhost:8050")
        time.sleep(5)
        
        pdf_path = os.path.join(output_dir, "report.pdf")
        print_settings = {
            "printBackground": True,
            "paperWidth": 8.3,
            "paperHeight": 11.7,
            "scale": 1.0
        }
        
        pdf_data = driver.execute_cdp_cmd("Page.printToPDF", print_settings)
        with open(pdf_path, "wb") as f:
            f.write(base64.b64decode(pdf_data['data']))
        
        return pdf_path
        
    except Exception as e:
        st.error(f"Report generation failed: {str(e)}")
        logging.error(f"Report generation error: {str(e)}")
        return None
        
    finally:
        # Cleanup resources
        try:
            if driver:
                driver.quit()
        except:
            pass
            
        if dash_process:
            try:
                dash_process.terminate()
                dash_process.wait(timeout=5)
            except:
                try:
                    dash_process.kill()
                except:
                    pass
        
        kill_dash_app(8050)

def wait_for_dash_app(timeout=30):
    """Check if Dash app is ready"""
    start_time = time.time()
    while time.time() - start_time < timeout:
        try:
            response = requests.get("http://localhost:8050/_alive", timeout=5)
            if response.status_code == 200:
                return True
        except requests.exceptions.RequestException:
            time.sleep(2)
    return False


def generate_pdf_file(driver, output_dir):
    """Generate the PDF file with proper settings"""
    print_settings = {
        "recentDestinations": [{
            "id": "Save as PDF",
            "origin": "local",
            "account": "",
        }],
        "selectedDestinationId": "Save as PDF",
        "version": 2,
        "isHeaderFooterEnabled": False,
        "isLandscapeEnabled": True,
        'printBackground': True,
        'paperHeight': 11.7,
        'paperWidth': 8.3,
        'scale': 1.0
    }
    
    pdf_data = driver.execute_cdp_cmd("Page.printToPDF", print_settings)
    pdf_path = os.path.join(output_dir, "report.pdf")
    
    with open(pdf_path, "wb") as f:
        f.write(base64.b64decode(pdf_data['data']))
    
    return pdf_path

def log_errors(process):
    """Log any errors from the subprocess"""
    if process:
        try:
            stdout, stderr = process.communicate(timeout=5)
            if stdout:
                logging.error(f"Dash stdout: {stdout}")
            if stderr:
                logging.error(f"Dash stderr: {stderr}")
        except subprocess.TimeoutExpired:
            logging.error("Process did not terminate when logging errors")

def cleanup_resources(driver, process):
    """Clean up all resources in proper order"""
    # Close driver first
    if driver:
        try:
            driver.quit()
        except:
            pass
    
    # Then terminate process
    if process:
        try:
            process.terminate()
            try:
                process.wait(timeout=5)
            except subprocess.TimeoutExpired:
                process.kill()
        except:
            pass
    
    # Final check to ensure Dash is gone
    kill_dash_app(8050)

def validate_inputs(name, file1, file2):
    """Validate user inputs before processing"""
    if not name.strip():
        st.error("Please enter a valid patient name")
        return False
    if not file1 or not file2:
        st.error("Please upload both data files")
        return False
    
    return True



def main():
    st.set_page_config(
        page_title="ÐžÑ‚Ñ‡ÐµÑ‚ Metaboscan",
        page_icon="ðŸ¥",
        layout="centered",
        initial_sidebar_state="collapsed"
    )
    
    with st.form("report_form"):
        st.header("Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ðµ")
        
        cols = st.columns(3)
        with cols[0]:
            name = st.text_input("ÐŸÐ¾Ð»Ð½Ð¾Ðµ Ð¸Ð¼Ñ (Ð¤Ð˜Ðž)", placeholder="Ð˜Ð²Ð°Ð½Ð¾Ð² Ð˜Ð²Ð°Ð½ Ð˜Ð²Ð°Ð½Ð¾Ð²Ð¸Ñ‡")
        with cols[1]:
            age = st.number_input("Ð’Ð¾Ð·Ñ€Ð°ÑÑ‚", min_value=0, max_value=120, value=47)
        with cols[2]:
            gender = st.selectbox("ÐŸÐ¾Ð»", ("Ðœ", "Ð–"), index=0)
        
        date = st.date_input("Ð”Ð°Ñ‚Ð° Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°", datetime.now(), format="DD.MM.YYYY")
        
        st.header("Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ")
        risk_params = st.file_uploader(
            "ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ñ€Ð¸ÑÐºÐ° (Excel)",
            type=["xlsx", "xls", "xlsm"],
            key="risk_params"
        )
        metabolomic_data = st.file_uploader(
            "ÐœÐµÑ‚Ð°Ð±Ð¾Ð»Ð¾Ð¼Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ñ„Ð¸Ð»ÑŒ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð° (Excel)",
            type=["xlsx", "xls"],
            key="metabolomic_data"
        )
        
        submitted = st.form_submit_button("Ð¡Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¾Ñ‚Ñ‡ÐµÑ‚", type="primary")
    
    if submitted and validate_inputs(name, risk_params, metabolomic_data):
        patient_info = {
            "name": name.strip(),
            "age": age,
            "date": date.strftime("%d.%m.%Y"),
            "gender": gender,
        }
        
        with st.spinner("ðŸ”¬ Ð§Ð¸Ñ‚Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸ Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ñ‚Ñ‡ÐµÑ‚. Ð­Ñ‚Ð¾ Ð·Ð°Ð¹Ð¼ÐµÑ‚ Ð½Ðµ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð¼Ð¸Ð½ÑƒÑ‚Ñ‹..."):
            with tempfile.TemporaryDirectory() as temp_dir:
                try:
                    # Save uploaded files temporarily
                    risk_params_path = os.path.join(temp_dir, "risk_params.xlsx")
                    with open(risk_params_path, "wb") as f:
                        f.write(risk_params.getbuffer())

                    # Calculate ratios and risks
                    metabolomic_data_with_ratios = calculate_metabolite_ratios(metabolomic_data)
                    metabolomic_data_with_ratios_path = os.path.join(temp_dir, "metabolomic_data.xlsx")
                    metabolomic_data_with_ratios.to_excel(metabolomic_data_with_ratios_path, index=False)
                    
                    risk_params_exp = prepare_final_dataframe(risk_params_path, metabolomic_data_with_ratios_path)
                    risk_params_exp_path = os.path.join(temp_dir, "risk_exp_params.xlsx")
                    risk_params_exp.to_excel(risk_params_exp_path, index=False)
                        
                    risk_scores = calculate_risks(risk_params_exp, metabolomic_data_with_ratios)
                    st.write(pd.read_excel(risk_params_exp_path))
                    st.write(risk_scores)
                    # Save risk scores as excel in temp_dir
                    risk_scores_path = os.path.join(temp_dir, "risk_scores.xlsx")
                    risk_scores.to_excel(risk_scores_path, index=False)

                    # Generate report
                    report_path = generate_pdf_report(
                        patient_info,
                        risk_scores_path,
                        risk_params_exp_path,
                        metabolomic_data_with_ratios_path,
                        temp_dir
                    )
                    
                    if report_path and os.path.exists(report_path):
                        st.success("âœ… ÐžÑ‚Ñ‡ÐµÑ‚ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ ÑÑ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½!")
                        with open(report_path, "rb") as f:
                            st.download_button(
                                label="ðŸ“¥ Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Ð¾Ñ‚Ñ‡ÐµÑ‚",
                                data=f.read(),
                                file_name=f"Report_{name.replace(' ', '_')}_{date.strftime('%Y%m%d')}.pdf",
                                mime="application/pdf",
                            )
                        
                        # with st.expander("ðŸ“„ Report Preview", expanded=True):
                        #     base64_pdf = base64.b64encode(open(report_path, "rb").read()).decode('utf-8')
                        #     st.markdown(
                        #         f'<iframe src="data:application/pdf;base64,{base64_pdf}" width="100%" height="800" style="border:none;"></iframe>',
                        #         unsafe_allow_html=True
                                
                        #     )
                        
                    else:
                        st.error("Failed to generate report. Please check the console for errors.")
                        
                except Exception as e:
                    st.error(f"An error occurred: {str(e)}")

if __name__ == "__main__":
    main()